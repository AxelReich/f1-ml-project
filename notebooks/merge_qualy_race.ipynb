{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a515e36-ba21-40fc-a0e8-58cb5035849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Processing and Merging ---\n",
      "Loaded 460 rows from 25 qualifying files.\n",
      "Loaded 459 rows from 25 race files.\n",
      "\n",
      "--- Success! ---\n",
      "Master file saved to: /Users/axelreich/Library/CloudStorage/OneDrive-FloridaStateUniversity/Semester8/DataMining/f1-ml-project/data/processed/2025_master_results.csv\n",
      "Final dataset has 460 rows and 14 columns.\n",
      "\n",
      "--- Script Finished. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/761wm_x53rxftvp659wnr6mc0000gn/T/ipykernel_40707/3772992117.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_qualy_data = pd.concat(qualy_df_list, ignore_index=True)\n",
      "/var/folders/6f/761wm_x53rxftvp659wnr6mc0000gn/T/ipykernel_40707/3772992117.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_race_data = pd.concat(race_df_list, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# --- Setup Paths ---\n",
    "# Define the paths to read from\n",
    "BASE_DIR = Path(\"../data\")\n",
    "RAW_DIR = BASE_DIR / \"raw\" \n",
    "RAW_QUALY_DIR = RAW_DIR / \"qualifying\" / \"2025\"\n",
    "RAW_RACE_DIR = RAW_DIR / \"race\" / \"2025\"\n",
    "\n",
    "# Define the path to write to\n",
    "PROCESSED_DIR = BASE_DIR / \"processed\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"--- Starting Data Processing and Merging ---\")\n",
    "\n",
    "try:\n",
    "    # --- 1. Load all Qualifying CSVs ---\n",
    "    # Get a list of all CSV files in the raw qualifying directory\n",
    "    qualy_csv_files = list(RAW_QUALY_DIR.glob(\"*.csv\"))\n",
    "    \n",
    "    if not qualy_csv_files:\n",
    "        print(f\"Error: No qualifying CSV files found in {RAW_QUALY_DIR}\")\n",
    "        print(\"Please run 'fetch_qualy_results.py' first.\")\n",
    "    else:\n",
    "        # Read each CSV into a DataFrame and combine them into one\n",
    "        qualy_df_list = [pd.read_csv(f) for f in qualy_csv_files]\n",
    "        all_qualy_data = pd.concat(qualy_df_list, ignore_index=True)\n",
    "        print(f\"Loaded {len(all_qualy_data)} rows from {len(qualy_csv_files)} qualifying files.\")\n",
    "        \n",
    "        # --- 2. Load all Race CSVs ---\n",
    "        race_csv_files = list(RAW_RACE_DIR.glob(\"*.csv\"))\n",
    "        \n",
    "        if not race_csv_files:\n",
    "            print(f\"Error: No race CSV files found in {RAW_RACE_DIR}\")\n",
    "            print(\"Please run 'fetch_race_results.py' first.\")\n",
    "        else:\n",
    "            race_df_list = [pd.read_csv(f) for f in race_csv_files]\n",
    "            all_race_data = pd.concat(race_df_list, ignore_index=True)\n",
    "            print(f\"Loaded {len(all_race_data)} rows from {len(race_csv_files)} race files.\")\n",
    "\n",
    "            # --- 3. Prepare Data for Merging ---\n",
    "            \n",
    "            # To avoid confusion, we rename the 'Position' column in both tables\n",
    "            all_qualy_data.rename(columns={'Position': 'QualyPos'}, inplace=True)\n",
    "            all_race_data.rename(columns={'Position': 'RacePos'}, inplace=True)\n",
    "            \n",
    "            # Define the key columns to join on. This \"associates\" the data.\n",
    "            merge_keys = ['Year', 'RoundNumber', 'EventName', 'FullName', 'TeamName']\n",
    "            \n",
    "            # Define the race-specific columns we want to add\n",
    "            race_columns_to_add = [\n",
    "                'GridPosition', 'RacePos', 'Status', 'Points', 'Laps'\n",
    "            ]\n",
    "            \n",
    "            # Create the final DataFrame to merge\n",
    "            # We must include the merge_keys + the new columns\n",
    "            race_data_subset = all_race_data[merge_keys + race_columns_to_add]\n",
    "\n",
    "            # --- 4. Merge the DataFrames ---\n",
    "            # We use a 'left' merge to keep all qualifying results\n",
    "            # and add race results where they exist.\n",
    "            master_results_df = pd.merge(\n",
    "                all_qualy_data,\n",
    "                race_data_subset,\n",
    "                on=merge_keys,\n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # Sort the final data for readability\n",
    "            master_results_df.sort_values(by=['Year', 'RoundNumber', 'QualyPos'], inplace=True)\n",
    "\n",
    "            # --- 5. Save the Final Processed File ---\n",
    "            YEAR = all_qualy_data['Year'].min() # Get the year from the data\n",
    "            output_filename = f\"2025_master_results.csv\"\n",
    "            output_path = PROCESSED_DIR / output_filename\n",
    "            \n",
    "            master_results_df.to_csv(output_path, index=False)\n",
    "            \n",
    "            print(f\"\\n--- Success! ---\")\n",
    "            print(f\"Master file saved to: {output_path.resolve()}\")\n",
    "            print(f\"Final dataset has {len(master_results_df)} rows and {len(master_results_df.columns)} columns.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- An Error Occurred ---\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please check that the raw data folders and files exist.\")\n",
    "\n",
    "print(\"\\n--- Script Finished. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c90b7a-3211-4450-9443-6919913559ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
